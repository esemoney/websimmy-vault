source: https://websim.ai/c/7Ujm7nwnqEf55dS54

# Figma Prototyping Case Study: Designing Interfaces for Human-Autonomous Agent Teaming

This case study demonstrates how the interface design tool Figma can be used to rapidly prototype complex human-AI interactions, such as those needed for commanding autonomous military agents. We walk through the process of iteratively designing and testing a concept interface for a multi-domain autonomous mission commander.

## Project Overview

The goal was to design a cross-platform interface that allows military operators to plan, monitor, and dynamically adjust missions carried out by teams of autonomous air, ground, and sea vehicles. Key user flows included:

- Specifying mission objectives, parameters and rules of engagement
- Real-time mission status tracking and human intervention
- Coordinating heterogeneous autonomous assets across domains
- After-action review and autonomous agent performance analysis

## Design Process

1. **Empathy research** - Observed and interviewed operators to understand mental models, pain points and latent needs.
2. **Sketching workshops** - Rapidly ideated interface concepts with users to explore the solution space.
3. **Wireframing sprint** - Quickly built out ideas in low-fidelity wireframes to test and iterate core workflows.
4. **Visual design** - Developed an intuitive visual language for data encoding and iconography.
5. **Interactive prototyping** - Simulated mission planning and monitoring interactions in Figma to get feedback.
6. **Concept validation** - Tested the prototype with operators in high-fidelity simulations to assess utility and usability.

![Storyboard depicting key military operator tasks](https://mcoai.dplmi.mit.edu/images/storyboard.jpg)

Fig 1. Storyboarding key operator tasks helped identify critical moments for interface assistance

A key insight that emerged was that mission planning is distributed across time and space. The interface needed to support asynchronous collaboration between planning and operations staff.

## Designing for Human-Autonomous Teaming

Prototyping the multi-domain mission interface in Figma highlighted important design principles for human-AI collaboration:

### Support Flexible Autonomy

Scalable interfaces are needed for operators to interact with multiple AI agents at varying levels of granularity, from high-level objective setting to detailed tasking when required.

### Explain Agent Rationale

Interfaces should provide on-demand rationale and execution traces to help calibrate operator trust in the AI agents' decisions and actions.

### Enable Effortless Supervision

Ambient status displays and timely alerts are critical for maintaining operator situation awareness without inducing cognitive overload.

### Allow Transparent Overrides

Clear mechanisms for operators to adjust or veto agent actions are essential, with the AI system adapting its future behavior based on these interventions.

![Figma prototype screens for autonomous mission control](https://mcoai.dplmi.mit.edu/images/figma-screens.png)

Fig 2. Key Figma prototype screens illustrating an explanation overlay and manual control interface

## Lessons Learned

Creating realistic interactive simulations in Figma was invaluable for uncovering nuanced human-AI interaction challenges that may have been missed in static designs, such as:

- Handling situations of degraded communication or partial autonomy
- Visualizing evolving world state and agent knowledge over time
- Avoiding mode confusion between different levels of autonomy
- Supporting what-if query and contingency planning workflows

The high-fidelity Figma prototype served as an effective tool for cross-disciplinary conversations about the art of the possible for human-AI teaming. It accelerated iteration cycles and improved the quality of feedback from end users and engineering stakeholders.

Ultimately, this case study illustrates how Figma can be a powerful medium for envisioning and prototyping next-generation interfaces at the cutting edge of human-AI interaction design, paving the way for more effective real-world human-machine collaboration.